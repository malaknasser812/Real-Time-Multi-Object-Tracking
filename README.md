# ğŸ¯ Real-Time Multi-object Tracking on Selection 

This project is a real-time multi-object tracking application using **OpenCV** and **Python**, where users can:
- Select and track multiple objects from a live webcam feed.
- Record tracking sessions as video, and save the recorded video.
- Analyze and save movement statistics such as distance and speed.
- Plot the motion path of each tracked object.

---

## ğŸ“¦ Features

### âœ… Real-Time Object Tracking
- Press **`s`** to select one or more objects using your mouse.
- Each object is given a unique ID and tracked continuously.
- Tracking overlays include bounding boxes and labels.

### âœ… Tracker Management
- Press **`u`** to stop tracking all currently selected objects.
- Previously tracked objects are not lost; their history remains saved.

### âœ… Video Recording
- Press **`r`** to start recording the live stream.
- Press **`x`** to stop and save the video.

### âœ… Post-Tracking Statistics
- Press **`q`** to quit the app
After quitting the app:
- The application computes the **total distance traveled** and **average speed** for each tracked object.
- All stats are saved as `tracking_stats.csv`.
- Motion paths are visualized using `matplotlib`.
- Recorded video (if found) will be saved as 'tracked_output.mp4'

---

## ğŸ“ Output Files

- `tracked_output.mp4` â€“ Optional video file of the tracking session.
- `tracking_stats.csv` â€“ CSV file with object tracking stats.
- *(Optional)* `motion_paths.png` â€“ Save the motion path visualization if desired.

---
## ğŸ›  Implementation Details

The project is implemented in Python using OpenCV and other scientific libraries. Here's a breakdown of the core components and logic:

### ğŸ“Œ 1. Initialization

- The system uses `cv2.VideoCapture(0)` to open the webcam stream.
- All active and archived tracked objects are managed using two lists:
  - `active_trackers`: stores objects currently being tracked.
  - `all_trackers`: stores all objects ever tracked for analysis, even if unselected.

```python
cap = cv2.VideoCapture(0)
active_trackers = []
all_trackers = []
object_id = 0
frame_count = 0

```

### ğŸ§  2. TrackedObject Class
- Each object selected for tracking is wrapped in a custom class to store:
- The tracker object (cv2.legacy.TrackerCSRT_create())
- The ROI selected by the user
- A unique ID
- A list of its center positions during motio
- Start and end frame indices (used to calculate duration)
- A flag active indicating whether it's still being tracked

```python
class TrackedObject:
    def __init__(self, tracker, roi, object_id, start_frame):
        self.tracker = tracker
        self.roi = roi
        self.id = object_id
        self.positions = []
        self.start_frame = start_frame
        self.end_frame = start_frame
        self.active = True
```
### ğŸ¥ 3. Object Tracking Loop
- Each frame is processed in a loop.
- If an object is active, the system updates its tracker.
- If tracking is successful, the new bounding box is drawn and the objectâ€™s center is recorded.
- If tracking fails (e.g. object moves out of frame), it is marked as inactive but not deleted.
```python
for obj in active_trackers:
    if obj.active:
        success, box = obj.tracker.update(frame)
        if success:
            center = compute_center(box)
            obj.positions.append(center)
            obj.end_frame = frame_count
        else:
            obj.active = False
            active_trackers.remove(obj)
```


### ğŸ–± 4. User Controls
- s: User selects a new object using cv2.selectROI. A new tracker is initialized and added.
- u: Clears all active trackers but keeps the history in all_trackers.
- r: Starts recording the live feed into tracked_output.mp4.
- x: Stops and saves the video file.
- q: Quits the application and generates final analysis.


### ğŸ“ˆ 5. Motion Analysis
- After quitting, statistics are computed for each tracked object:
- Total Distance: Sum of Euclidean distances between consecutive center points.
- Average Speed: Total distance divided by number of frames.

```python
distances = [
    np.linalg.norm(np.array(obj.positions[i+1]) - np.array(obj.positions[i]))
    for i in range(len(obj.positions) - 1)
]
total_distance = sum(distances)
avg_speed = total_distance / lifetime
```


### ğŸ“Š 6. Visualization and Export
- A trajectory plot is created using matplotlib, showing the path each object followed.
- A CSV file tracking_stats.csv is saved with summary metrics for each object:
- - Object ID
- - Total distance
- - Average speed

Duration (seconds)
```python
plt.plot(positions[:, 0], positions[:, 1], marker='o', label=f'Object ID {obj.id}')
df.to_csv("tracking_stats.csv", index=False)
```


### ğŸ’¾ Outputs
- tracked_output.mp4: Optional recording of the session.
- tracking_stats.csv: Table of object motion statistics.
- Matplotlib motion plot (displayed, can be saved if needed).


---
## ğŸš€ Instructions for Deployment

Follow the steps below to set up and run the application locally:

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/object-tracking-opencv.git
cd object-tracking-opencv
```
### 2ï¸âƒ£ Install Dependencies
```bash
pip install opencv
pip install imutils 
pip install matplotlib 
pip install pandas 
pip install numpy
```
### 3ï¸âƒ£ Run the file

---

## ğŸ‘©â€ğŸ’» Author
**Malak Nasser** | AI Engineer <br>
ğŸ“§ [E-mail](mallaknasser812@gmail.com) <br>
ğŸ”— [LinkedIn](https://www.linkedin.com/in/malak-nasser-752ab0214/) 

